{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\michem\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6fdcc7756b0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvis_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mskvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from object_detection.protos import string_int_label_map_pb2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from PIL import Image\n",
    "import time\n",
    "import KCF\n",
    "import cv2\n",
    "import sys\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "import skvideo.io\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "PATH_TO_CKPT = './model_files/faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = './labels/coco_label_map.pbtxt'\n",
    "NUM_CLASSES =90\n",
    "\n",
    "'''\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "        \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "#category_index.update({0: {'id': 0, 'name': 'Detection Lost'}})\n",
    "'''\n",
    "def load_image_into_numpy_array(image):\n",
    "    return np.asarray(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Extract frames from videos (Run it only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "VIDEO='./bacchiglione.20160229_130015_part1.mp4'\n",
    "RESULTS_PATH= './frames2'\n",
    "#VIDEO='D:/Image Analysis Algorithms/drones/Drones algorithms/object_detection/input/dummy1.mp4'\n",
    "#RESULTS_PATH='D:/Image Analysis Algorithms/drones/Drones algorithms/object_detection/input_images/dummy'\n",
    "\n",
    "#f_list = os.listdir(VIDEO_DIR)\n",
    "#f_list_mp4 = [each for each in f_list if '.mp4' in each]\n",
    "#for fname in tqdm(f_list_mp4):\n",
    "    #path = os.path.join(file_path, f)\n",
    "    #VIDEO_NAME='dummy1'\n",
    "#    VIDEO_PATH=os.path.join(VIDEO_DIR, fname)\n",
    "metadata = skvideo.io.ffprobe(VIDEO)\n",
    "frames = []\n",
    "fps = metadata['video']['@r_frame_rate']\n",
    "fps = fps.split(sep='/')\n",
    "fps = int(fps[0])/int(fps[1])\n",
    "width = int(metadata['video']['@width'])\n",
    "height = int(metadata['video']['@height'])\n",
    "sequence = skvideo.io.vreader(VIDEO)\n",
    "#os.mkdir(os.path.join(RESULTS_PATH,fname))\n",
    "for i, frame in enumerate(sequence):\n",
    "    to_write = Image.fromarray(frame)\n",
    "    to_write.save(os.path.join(RESULTS_PATH,'image'+str(i)+'.jpg'))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(bbb1, bbb2):\n",
    "    \n",
    "    bb1 = [bbb1[0], bbb1[0]+bbb1[2], bbb1[1], bbb1[1]+bbb1[3]]\n",
    "    bb2 = [bbb2[0], bbb2[0]+bbb2[2], bbb2[1], bbb2[1]+bbb2[3]]\n",
    "    \n",
    "    assert bb1[0] < bb1[1]\n",
    "    assert bb1[2] < bb1[3]\n",
    "    assert bb2[0] < bb2[1]\n",
    "    assert bb2[2] < bb2[3]\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1[0], bb2[0])\n",
    "    y_top = max(bb1[2], bb2[2])\n",
    "    x_right = min(bb1[1], bb2[1])\n",
    "    y_bottom = min(bb1[3], bb2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1[1] - bb1[0]) * (bb1[3] - bb1[2])\n",
    "    bb2_area = (bb2[1] - bb2[0]) * (bb2[3] - bb2[2])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou\n",
    "\n",
    "def print_track(boundingbox, width, height, frame, idx, col, cus):\n",
    "    cv2.rectangle(frame,(boundingbox[0],boundingbox[1]),\n",
    "                  (boundingbox[0]+boundingbox[2],boundingbox[1]+boundingbox[3]),\n",
    "                  col, 1)                       \n",
    "    cv2.putText(frame,\n",
    "                (str)(idx),\n",
    "                ((int)(boundingbox[0]+boundingbox[2]/2), (int)(boundingbox[1]+boundingbox[3]/2)),\n",
    "                cv2.FONT_HERSHEY_PLAIN, 2, (255,255,51), 2)\n",
    "    return\n",
    "\n",
    "def box_trans(box): #transform from (ymin, xmin, ymax, xmax)[norm] to (left, top, width, height)[non-norm]\n",
    "    box = [box[0] * height, box[1] * width, box[2] * height, box[3] * width]\n",
    "    box = list(map(int, box))\n",
    "    box = [box[1], box[0], abs(box[3]-box[1]), abs(box[2]-box[0])]\n",
    "    return box\n",
    "\n",
    "def rev_box_trans(box_list): #transform from (left, top, width, height)[non-norm] to (ymin, xmin, ymax, xmax)[non-norm]\n",
    "    res = []\n",
    "    for box in box_list:\n",
    "        temp = [box[1], box[0], box[3]+box[1], box[2]+box[0]]\n",
    "        res = res + [temp]\n",
    "    return res\n",
    "\n",
    "def to_norm(box_list, height, width): #transform from (left, top, width, height)[non-norm] to (ymin, xmin, ymax, xmax)[norm]\n",
    "    res = []\n",
    "    for box in box_list:\n",
    "        temp = [box[1]/height, box[0]/width, (box[3]+box[1])/height, (box[2]+box[0])/width]\n",
    "        res = res + [temp]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Detection using Tracking algorithm</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tracking(frames,IMAGE_PATH,RESULTS_PATH):\n",
    "    global height, width\n",
    "   \n",
    "    tracks = []\n",
    "    tracked_boxes = []\n",
    "    frameList = []\n",
    "    buffer = []\n",
    "    #PARAMETERS\n",
    "   \n",
    "    detection_rate = 300 #detection every this number of frames\n",
    "    dlost_thres = 3 #delete track if detection lost for this number of frames\n",
    "    reset_thres = 15 #clear the screen from tracked boxes every this number of frames\n",
    "    save_iou = 0.33 #if you find an iou between current box and tracked boxes above that threshold don't create a new id\n",
    "    rectify_iou = 0.7 #if the max iou between the tracked box and a detection box is bellow that rectify the tracked box\n",
    "    \n",
    "   \n",
    "\n",
    "    temp=frames\n",
    "                \n",
    "    boundingbox=[700,0,29,18]\n",
    "    #boundingbox=[ 0.37799576, 0.44462934, 0.46364778, 0.6029203]                         \n",
    "    for idf, f in enumerate(tqdm(temp)):\n",
    "                    \n",
    "        frame = Image.open(os.path.join(IMAGE_PATH, f))\n",
    "        image=f\n",
    "        # the array based representation of the image will be used later in order to prepare the\n",
    "        # result image with boxes and labels on it.\n",
    "        frame_np = load_image_into_numpy_array(frame)\n",
    "        write_on = frame_np.copy()\n",
    "        height = frame_np.shape[0]\n",
    "        width = frame_np.shape[1]\n",
    "                    \n",
    "        if idf==0:\n",
    "            #print(True)\n",
    "            tracker = KCF.kcftracker(False, True, True, False)  # hog, fixed_window, multiscale, lab\n",
    "            #tracks = tracks + [tracker]\n",
    "            tracked_boxes = [boundingbox]\n",
    "            tracker.init(boundingbox, frame_np)  \n",
    "        else:\n",
    "            #print(boundingbox)\n",
    "            boundingbox = tracker.update(frame_np)\n",
    "            \n",
    "            tracked_boxes = tracked_boxes+[boundingbox]\n",
    "            \n",
    "            \n",
    "        frameList.append([0,1,1,boundingbox,boundingbox,1])\n",
    "        #print(frameList[idf])\n",
    "        #print(tracked_boxes)\n",
    "            #visualize detection \n",
    "        boundingbox_rev=[]\n",
    "        boundingbox_rev=[[boundingbox[0]/width,boundingbox[1]/height,boundingbox[2]/width,boundingbox[3]/height]]\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(write_on,\n",
    "                        np.array(boundingbox_rev),                        \n",
    "                        [1],\n",
    "                        [0.57013863],\n",
    "                        {1: {'id': 1, 'name': 'person'}},\n",
    "                        use_normalized_coordinates=False,\n",
    "                        max_boxes_to_draw=500,\n",
    "                        line_thickness=1,\n",
    "                        min_score_thresh=0)\n",
    "        '''\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                        write_on,\n",
    "                        np.squeeze(boxes, axis=0),\n",
    "                        np.squeeze(classes, axis=0).astype(np.int32),\n",
    "                        np.squeeze(scores, axis=0),\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        max_boxes_to_draw=500,\n",
    "                        line_thickness=1,\n",
    "                        min_score_thresh=confidence_drop)\n",
    "        '''\n",
    "        \n",
    "        cv2.putText(write_on,(str)(frameList[idf][0]),((int)(frameList[idf][3][0]+frameList[idf][3][2]/2), (int)(frameList[idf][3][1]+frameList[idf][3][3]/2)), \n",
    "                            cv2.FONT_HERSHEY_PLAIN, 2, (255,255,51), 2)\n",
    "        \n",
    "        buffer += [write_on]\n",
    "                \n",
    "                                                           \n",
    "                    \n",
    "                               \n",
    "        '''\n",
    "                       \n",
    "         if video_out==False:  # Write results on Image sequence                          \n",
    "             to_write = Image.fromarray(write_on)\n",
    "             to_write.save(os.path.join(RESULTS_PATH, image+'_output.jpg'))\n",
    "             image_to_json(boxes)\n",
    "             results_to_txt(boxes)      \n",
    "           \n",
    "        '''\n",
    "        \n",
    "       \n",
    "    \n",
    "    to_write = np.array(buffer)\n",
    "    if(os.path.join('./analyzed_videos',RESULTS_PATH))==False:\n",
    "        os.mkdir(os.path.join('./analyzed_videos',RESULTS_PATH))\n",
    "    writer = skvideo.io.FFmpegWriter(os.path.join('./analyzed_videos',RESULTS_PATH,'analyzed.avi'), \n",
    "                                     inputdict={'-r': str(1)},\n",
    "                                     outputdict={'-vcodec': 'libvpx', '-b': '500000', '-r': str(2)}) \n",
    "                                     #outputdict={'-vcodec': 'libx264', '-b': '2000000', '-framerate': str(1)})\n",
    "    \n",
    "    \n",
    "                                 \n",
    "    \n",
    "    \n",
    "    for i in range(to_write.shape[0]):\n",
    "        writer.writeFrame(to_write[i])\n",
    "    writer.close()\n",
    "        \n",
    "        #if(video):\n",
    "            # writer = np.array(buffer)\n",
    "            # skvideo.io.vwrite(os.path.join(PATH_TO_VIDEO_OUTPUT,PATH_TO_VIDEO.split(sep='/')[-1].split(sep='.')[0]+'_analyzed.avi'), writer)\n",
    "            ##CODE TO WRITE VIDEO WITH BETTER QUALITY\n",
    "            #to_write = np.array(buffer)\n",
    "            #writer = skvideo.io.FFmpegWriter(os.path.join(PATH_TO_VIDEO_OUTPUT,PATH_TO_VIDEO.split(sep='/')[-1].split(sep='.')[0]+'_analyzed.avi'), \n",
    "            #                                 outputdict={'-vcodec': 'libx264', '-b': '2000000', '-framerate': str(5)})\n",
    "            #for i in range(to_write.shape[0]):\n",
    "            #    writer.writeFrame(to_write[i])\n",
    "            #writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image sequence (video_in==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "def sort_nicely(l):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load all images and initial bbx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 23.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 39.02it/s]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#initial_bbx=\n",
    "\n",
    "\n",
    "IMAGES_DIR='./extracted_frames'\n",
    "f_list = os.listdir(IMAGES_DIR)\n",
    "\n",
    "for folder in f_list:\n",
    "    #print(folder)\n",
    "    #TEST_IMAGE_PATHS.sort(key=alphanum_key)\n",
    "    f_list_im = os.listdir(str(IMAGES_DIR+'/'+folder))\n",
    "    f_list_im.sort(key=alphanum_key)\n",
    "    #print(f_list_im)\n",
    "    #print(str(IMAGES_DIR+'/'+folder))\n",
    "    run_tracking(f_list_im[0:10],str(IMAGES_DIR+'/'+folder),folder)\n",
    "    #print(f_list_im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Write result on video (video_out==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_tracking2(frames,IMAGE_PATH,RESULTS_PATH):\n",
    "    global height, width\n",
    "   \n",
    "    tracks = []\n",
    "    tracked_boxes = []\n",
    "    frameList = []\n",
    "    buffer = []\n",
    "    #PARAMETERS\n",
    "   \n",
    "    detection_rate = 300 #detection every this number of frames\n",
    "    dlost_thres = 3 #delete track if detection lost for this number of frames\n",
    "    reset_thres = 15 #clear the screen from tracked boxes every this number of frames\n",
    "    save_iou = 0.33 #if you find an iou between current box and tracked boxes above that threshold don't create a new id\n",
    "    rectify_iou = 0.7 #if the max iou between the tracked box and a detection box is bellow that rectify the tracked box\n",
    "   \n",
    "   \n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        with detection_graph.as_default():\n",
    "            with tf.Session(graph=detection_graph) as sess:\n",
    "                #image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "                # Each box represents a part of the image where a particular object was detected.\n",
    "                boxes_g = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                # Each score represent how level of confidence for each of the objects.\n",
    "                # Score is shown on the result image, together with the class label.\n",
    "                scores_g = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                classes_g = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                num_detections_g = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "                \n",
    "                \n",
    "                temp=frames\n",
    "                  \n",
    "                                \n",
    "                for idf, f in enumerate(tqdm(temp)):\n",
    "                    \n",
    "                    frame = Image.open(os.path.join(IMAGE_PATH, f))\n",
    "                    image=f\n",
    "                    # the array based representation of the image will be used later in order to prepare the\n",
    "                    # result image with boxes and labels on it.\n",
    "                    frame_np = load_image_into_numpy_array(frame)\n",
    "                   \n",
    "                \n",
    "                    write_on = frame_np.copy()\n",
    "                    height = frame_np.shape[0]\n",
    "                    width = frame_np.shape[1]\n",
    "                    # Actual detection.\n",
    "                    if(idf%detection_rate == 0):\n",
    "                        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "                        frame_np_expanded = np.expand_dims(frame_np, axis=0)\n",
    "                        (boxes, scores, classes, num_detections) = sess.run(\n",
    "                            [boxes_g, scores_g, classes_g, num_detections_g],\n",
    "                            feed_dict={image_tensor: frame_np_expanded})\n",
    "                       \n",
    "            \n",
    "                                                \n",
    "                        boxes_t=[] #initiallize transformed boxes storage\n",
    "            \n",
    "                        # Tracking\n",
    "                        if(idf > 0 and idf%reset_thres == 0): #reset boxes every reset_thres_th frame\n",
    "                            for idx, track in enumerate(tracks):\n",
    "                                if(tracks[idx]):\n",
    "                                    boundingbox = track.update(frame_np)\n",
    "                                    tracked_boxes[idx] = [boundingbox]\n",
    "                                else:\n",
    "                                    tracked_boxes[idx] = []\n",
    "                \n",
    "                        for bid, box in enumerate(np.squeeze(boxes, axis=0)): #transform detected boxes and search through\n",
    "                            box = box_trans(box)\n",
    "                            boxes_t = boxes_t + [box]\n",
    "                            #save new tracks\n",
    "                    \n",
    "                            save_flag = True\n",
    "                            for sbox in sum(tracked_boxes, []): #check all tracked boxes\n",
    "                                if(sbox): #if the sbox exists\n",
    "                                    if(get_iou(sbox, box) > save_iou): #if you find an iou above that threshold don't save a new box\n",
    "                                        save_flag = False    \n",
    "                            if (save_flag == True): #initiallize a new tracker (you found a box with no iou above the threshold)\n",
    "                                tracker = KCF.kcftracker(False, True, True, False)  # hog, fixed_window, multiscale, lab\n",
    "                                tracks = tracks + [tracker]\n",
    "                                tracked_boxes = tracked_boxes + [[box]]\n",
    "                                tracker.init(box, frame_np)\n",
    "            \n",
    "                    frameList = frameList + [[]]            \n",
    "                    for idx, track in enumerate(tracks):\n",
    "                        if (tracks[idx]):\n",
    "                                boundingbox = track.update(frame_np)\n",
    "                                if(idf%detection_rate == 0): #every 3rd frame\n",
    "                                    max_iou = 0\n",
    "                                    for idb, ibox in enumerate(boxes_t):\n",
    "                                        iou = get_iou(ibox, boundingbox)\n",
    "                                        if(iou >= max_iou):\n",
    "                                            max_iou_id = idb\n",
    "                                            max_iou = iou\n",
    "                                    if(max_iou > rectify_iou):\n",
    "                                        #keep\n",
    "                                        tracked_boxes[idx] = tracked_boxes[idx] + [boundingbox]\n",
    "                                        #frameList append\n",
    "                                        frameList[idf] = frameList[idf] + [[idx, \n",
    "                                                                           np.squeeze(classes, axis=0)[max_iou_id], \n",
    "                                                                           np.squeeze(scores, axis=0)[max_iou_id], \n",
    "                                                                           boundingbox, \n",
    "                                                                           boxes_t[max_iou_id],\n",
    "                                                                           1]]\n",
    "                                    elif(max_iou <= rectify_iou and max_iou > 0.1):\n",
    "                                        #rect\n",
    "                                        track.init(boxes_t[max_iou_id], frame_np)\n",
    "                                        boundingbox = track.update(frame_np)\n",
    "                                        tracked_boxes[idx] = tracked_boxes[idx] + [boundingbox]\n",
    "                                        frameList[idf] = frameList[idf] + [[idx, \n",
    "                                                                           np.squeeze(classes, axis=0)[max_iou_id], \n",
    "                                                                           np.squeeze(scores, axis=0)[max_iou_id], \n",
    "                                                                           boundingbox, \n",
    "                                                                           boxes_t[max_iou_id],\n",
    "                                                                           1]]\n",
    "                                    else:\n",
    "                                        tracked_boxes[idx] = tracked_boxes[idx] + [boundingbox]\n",
    "                                        counter = 0\n",
    "                                        if(idf >= detection_rate+dlost_thres-1):\n",
    "                                            for i in range(idf, idf-dlost_thres, -1):\n",
    "                                                try:\n",
    "                                                    the_score = frameList[i][[row[0] for row in frameList[i]].index(idx)][5]\n",
    "                                                except ValueError:\n",
    "                                                    the_score = -1\n",
    "                                                if(the_score == 0):\n",
    "                                                    counter = counter + 1\n",
    "                                        if(counter < dlost_thres-1):\n",
    "                                            #detection lost\n",
    "                                            tracker_bug=0\n",
    "                                            try:\n",
    "                                                frameList[idf] = frameList[idf] + [[idx,\n",
    "                                                                                    frameList[idf-1][[row[0] for row in frameList[idf-1]].index(idx)][1], \n",
    "                                                                                    frameList[idf-1][[row[0] for row in frameList[idf-1]].index(idx)][2], \n",
    "                                                                                    boundingbox, \n",
    "                                                                                    boundingbox,\n",
    "                                                                                    0]]\n",
    "                                            except ValueError:\n",
    "                                                tracker_bug=1\n",
    "                                            if(tracker_bug==1):\n",
    "                                                frameList[idf] = frameList[idf] + [[idx,\n",
    "                                                                                    np.squeeze(classes, axis=0)[max_iou_id], \n",
    "                                                                                    np.squeeze(scores, axis=0)[max_iou_id], \n",
    "                                                                                    boxes_t[max_iou_id], \n",
    "                                                                                    boxes_t[max_iou_id],\n",
    "                                                                                    0]]\n",
    "                                        else:\n",
    "                                            tracks[idx] = []\n",
    "                                            tracked_boxes[idx] = []\n",
    "                                else:\n",
    "                                    #no detection result\n",
    "                                    frameList[idf] = frameList[idf] + [[idx, \n",
    "                                                                        frameList[idf-1][[row[0] for row in frameList[idf-1]].index(idx)][1], \n",
    "                                                                        frameList[idf-1][[row[0] for row in frameList[idf-1]].index(idx)][2], \n",
    "                                                                        boundingbox, \n",
    "                                                                        boundingbox,\n",
    "                                                                        frameList[idf-1][[row[0] for row in frameList[idf-1]].index(idx)][5]]]\n",
    "\n",
    "                    #merge\n",
    "                    m_to_del = []\n",
    "                    for box1 in frameList[idf]:\n",
    "                        for box2 in frameList[idf]:\n",
    "                            if(box1[0] is not box2[0]):\n",
    "                                iou_m = get_iou(box1[3], box2[3])\n",
    "                                if(iou_m >= merge_iou):\n",
    "                                    #delete\n",
    "                                    tracks[max([box1[0], box2[0]])] = []\n",
    "                                    tracked_boxes[max([box1[0], box2[0]])] = []\n",
    "                                    m_to_del = m_to_del + [max([box1[0], box2[0]])]\n",
    "            \n",
    "                    new_m = []\n",
    "                    for i in m_to_del:\n",
    "                        if i not in new_m:\n",
    "                            new_m.append(i)\n",
    "                    for m in new_m:\n",
    "                        frameList[idf].pop([row[0] for row in frameList[idf]].index(m))               \n",
    "                \n",
    "                \n",
    "                    #visualize detection        \n",
    "                    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                        write_on,\n",
    "                        np.array(rev_box_trans([row[3] for row in frameList[idf]])),\n",
    "                        np.array([row[1] for row in frameList[idf]]).astype(np.int32),\n",
    "                        np.array([row[2] for row in frameList[idf]]),\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=False,\n",
    "                        max_boxes_to_draw=500,\n",
    "                        line_thickness=1,\n",
    "                        min_score_thresh=0)\n",
    "            \n",
    "                    for i in frameList[idf]:\n",
    "                        cv2.putText(write_on, \n",
    "                            (str)(i[0]),\n",
    "                            ((int)(i[3][0]+i[3][2]/2), (int)(i[3][1]+i[3][3]/2)), \n",
    "                            cv2.FONT_HERSHEY_PLAIN, 2, (255,255,51), 2)\n",
    "                    buffer += [write_on]\n",
    "                        \n",
    "                    if video_out==False:  # Write results on Image sequence                          \n",
    "                        to_write = Image.fromarray(write_on)\n",
    "                        to_write.save(os.path.join(RESULTS_PATH, image+'_output.jpg'))\n",
    "                        image_to_json(boxes)\n",
    "                        results_to_txt(boxes)      \n",
    "     \n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "    to_write = np.array(buffer)\n",
    "    writer = skvideo.io.FFmpegWriter(os.path.join('./analyzed videos',RESULTS_PATH,'analyzed.avi'), \n",
    "                                      outputdict={'-vcodec': 'libx264', '-b': '2000000', '-framerate': str(1)})\n",
    "    for i in range(to_write.shape[0]):\n",
    "        writer.writeFrame(to_write[i])\n",
    "    writer.close()\n",
    "        \n",
    "        #if(video):\n",
    "            # writer = np.array(buffer)\n",
    "            # skvideo.io.vwrite(os.path.join(PATH_TO_VIDEO_OUTPUT,PATH_TO_VIDEO.split(sep='/')[-1].split(sep='.')[0]+'_analyzed.avi'), writer)\n",
    "            ##CODE TO WRITE VIDEO WITH BETTER QUALITY\n",
    "            #to_write = np.array(buffer)\n",
    "            #writer = skvideo.io.FFmpegWriter(os.path.join(PATH_TO_VIDEO_OUTPUT,PATH_TO_VIDEO.split(sep='/')[-1].split(sep='.')[0]+'_analyzed.avi'), \n",
    "            #                                 outputdict={'-vcodec': 'libx264', '-b': '2000000', '-framerate': str(5)})\n",
    "            #for i in range(to_write.shape[0]):\n",
    "            #    writer.writeFrame(to_write[i])\n",
    "            #writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(video_out):\n",
    "    # writer = np.array(buffer)\n",
    "    # skvideo.io.vwrite(os.path.join(PATH_TO_VIDEO_OUTPUT,PATH_TO_VIDEO.split(sep='/')[-1].split(sep='.')[0]+'_analyzed.avi'), writer)\n",
    "    #CODE TO WRITE VIDEO WITH BETTER QUALITY\n",
    "    to_write = np.array(buffer)\n",
    "    if(video_in):\n",
    "        writer = skvideo.io.FFmpegWriter(os.path.join(RESULTS_PATH+'/',PATH_TO_VIDEO.split(sep='/')[-1].split(sep='.')[0]+'_analyzed.avi'), \n",
    "                                          outputdict={'-vcodec': 'libx264', '-b': '2000000', '-framerate': str(1)})\n",
    "    if video_in==False:\n",
    "         writer = skvideo.io.FFmpegWriter(os.path.join(RESULTS_PATH+'/analyzed.avi'), \n",
    "                                      outputdict={'-vcodec': 'libx264', '-b': '2000000', '-framerate': str(1)})\n",
    "    for i in range(to_write.shape[0]):\n",
    "        writer.writeFrame(to_write[i])\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Export single JSON for video input for Tracking algorithm</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(tracking):\n",
    "    all_frames = []\n",
    "    for idf, frame in enumerate(frameList):\n",
    "        target_dict = []\n",
    "        for target in frame:\n",
    "            target_dict += [{\"id\":target[0], \n",
    "                             \"left\":target[3][0], \n",
    "                             \"top\":target[3][1], \n",
    "                             \"width\":target[3][2], \n",
    "                             \"height\":target[3][3], \n",
    "                             \"type\":category_index[int(target[1])]['name'],\n",
    "                             \"confidence\":float(\"{0:.3f}\".format(target[2]))}]\n",
    "        if(target_dict):\n",
    "            frame_dict = {\"num\":idf, \"target\":target_dict}\n",
    "            all_frames += [frame_dict]\n",
    "            \n",
    " \n",
    "        \n",
    "\n",
    "    if(video_in):\n",
    "        son = {'sequence':{\"name\":PATH_TO_VIDEO.split(sep='/')[-1], \"width\":width, \"height\":height, \"fps\":float(\"{0:.3f}\".format(fps)), \"frame\":all_frames}}\n",
    "        with open(os.path.join(RESULTS_PATH+'/',PATH_TO_VIDEO.split(sep='/')[-1].rsplit(sep='.', maxsplit=1)[0]+'_analyzed.json'), 'w') as outfile:\n",
    "            json.dump(son, outfile, sort_keys=False, indent=1)\n",
    "        outfile.close()\n",
    "        \n",
    "  #  if video_in==False:   #no json\n",
    "  #      son = {'sequence':{\"name\":\"analyzed\", \"width\":width, \"height\":height, \"fps\":float(\"{0:.3f}\".format(fps)), \"frame\":all_frames}}\n",
    "  #      with open(os.path.join(RESULTS_PATH+'/analyzed.json'), 'w') as outfile:\n",
    "  #          json.dump(son, outfile, sort_keys=False, indent=1)\n",
    "  #      outfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
